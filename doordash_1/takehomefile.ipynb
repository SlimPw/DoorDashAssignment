{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9d02d538",
      "metadata": {
        "id": "9d02d538"
      },
      "source": [
        "![Doordash](https://raw.githubusercontent.com/interviewquery/takehomes/doordash_1/doordash_1/logo.png)\n",
        "# Overview\n",
        "\n",
        "In this exercise, you will use your machine learning experience to solve\n",
        "a straightforward but challenging prediction​ ​problem.​ ​The​ ​exercise​\n",
        "​contains two​​ parts​\n",
        "\n",
        "1. Building​ ​a​ ​machine​ ​learning​ model​ ​ ​for​ ​a​ ​prediction ​ task​\n",
        "2. Writing ​ an​ ​ application​ ​ to​ ​ make​ ​ ​predictions ​ using​ ​ ​that​ ​model.\n",
        "\n",
        "In Part 1, we would love to have you exhibit your modeling skills. You\n",
        "will be evaluated on the following - performance on the test set,\n",
        "feature engineering choices including features used and encoding of\n",
        "features, data processing, choice of models used, description of model\n",
        "performance and insights and observations from the​ ​model.\n",
        "\n",
        "Part 2 is your chance to show off your software engineering skills. This\n",
        "includes performance of the application, adherence to common software\n",
        "engineering patterns (unit tests, modular code, etc.) and ability to\n",
        "make educated​ ​trade-offs​ ​based​ ​on​ ​the​ ​given ​ constraints.​\n",
        "\n",
        "**NOTE:** For​ this part, you must use a production ready language like\n",
        "Python. Thus, please do not use R.\n",
        "\n",
        "# Problem ​Description\n",
        "\n",
        "When​ a​ ​consumer​ ​places​ ​an​ ​order​ ​on​ DoorDash,​​ we​ ​ show​ ​ the​ ​ ​expected ​\n",
        "​time of​​ ​delivery.​ ​It​ ​is​ ​very ​important​ ​for​ DoorDash to get this right, as it has a big impact on consumer experience. In this exercise, you will build a model to predict the\n",
        "estimated time taken for a delivery and write an application that can\n",
        "make these predictions.\n",
        "\n",
        "Concretely, for a given delivery you must predict the ​**total delivery\n",
        "duration seconds** , i.e., the time taken from\n",
        "\n",
        "- Start:​ ​the​ ​time​ ​consumer​ ​submits​ ​the​ ​order ​ (​`created_at`) ​ to​\n",
        "- End:​ ​when​ ​the​ ​order​ ​will​ ​be​ ​delivered​ to​ ​ ​the​ consumer​​\n",
        "​(`actual_delivery_time`).\n",
        "\n",
        "To​ ​help​ ​with​ ​this,​ ​we​ ​have​ ​provided\n",
        "\n",
        "-   `historical_data.csv`:​ ​table​ ​of​ ​historical​ ​deliveries\n",
        "\n",
        "-   `data_to_predict.json`: ​ ​Json​ ​list​ ​of​ ​deliveries​ ​that​ ​you​ ​must​\n",
        "    ​predict​ ​on​ ​(for ​​the​ ​second​ ​part)\n",
        "\n",
        "-   `data_description.txt`:​ ​ description​ ​ of​ ​ all​ ​ columns​ ​ in​​ `historical_data.csv`​ ​and​ ​details​ of​ `data_to_predict.json`\n",
        "\n",
        "# Requirements\n",
        "\n",
        "## Part ​ 1​\n",
        "\n",
        "-   Build a model to predict the total delivery duration seconds (as\n",
        "    defined above). Feel free to generate additional​ ​features​ ​from​ ​the ​ given​ ​ data​ ​ to​ ​ improve​ ​ model​ ​performance.​\n",
        "-   Explain a) model(s) used, b) how you evaluated your model\n",
        "    performance on the historical data, c) any data processing you\n",
        "    performed on the data, d) feature engineering choices you made\n",
        "    and e) other information​ ​you​ ​would​ ​like​ ​us​ ​to​ ​know​ ​about​ ​your​\n",
        "    ​modeling​ ​approach.\n",
        "-   Based ​ on​ ​ the​ ​ ​findings ​​from​ ​the​ ​model,​ list​​ ​recommendations​ to​​\n",
        "    ​reduce​ ​delivery​ ​time\n",
        "\n",
        "### Deliverables\n",
        "\n",
        "-   Submit one document that includes a write-up explaining your model,\n",
        "    choices made and discussion on the​ ​questions ​ above.​\n",
        "-   Submit​ ​the​ ​code​ ​used​ ​for​ ​this​ ​part\n",
        "\n",
        "## Part ​ 2​\n",
        "-   Write an application that accepts data from the json file\n",
        "    (`data_to_predict.json`), uses the model to make a prediction for each\n",
        "    delivery in the json file and writes out predictions to a new ​*tab separated file* (`tsv`) with​ ​columns​ ​-​ ​`delivery_id`, ​`predicted_delivery_seconds`\n",
        "\n",
        "-   Your predictions on this test data set will be evaluated using RMSE\n",
        "    (Root Mean Squared Error) and your ​ score​ ​ must​ ​ exceed​ ​ a​ ​ baseline​\n",
        "    ​ set​ ​ for​ ​ the​ ​ ​task.\n",
        "\n",
        "### Deliverables\n",
        "\n",
        "-   Code that ​​outputs a​ ​`tsv`​ ​file​ ​that​ ​gives ​the​​ ​prediction​ ​for​ ​the​\n",
        "     `data_to_predict.json` data.​ This application (that makes\n",
        "    predictions) must be runnable from the command line with\n",
        "    `data_to_predict.json` passed as input. Include instructions for\n",
        "    running the code (dependencies,​ ​packages​ ​required,​ ​etc.)\n",
        "\n",
        "# Notes\n",
        "\n",
        "We expect the exercise to take 5-6 hours in total, but feel free to\n",
        "spend as much time as you like on it. Feel free to​ ​use​ ​any​ ​open​ ​source​\n",
        "​packages​ ​for​ ​the​ ​task.\n",
        "\n",
        "**Thank**​ ​**you**​ ​**for**​ ​**your**​ ​**hard**​ ​**work!**​ ​**Please**​ ​**let**​\n",
        "​**us**​ ​**know**​ ​**if**​ ​**you**​ ​**have**​ ​**any**​ ​**questions.**​ ​**Good**​\n",
        "​**luck!**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d90a6aa",
      "metadata": {
        "id": "7d90a6aa",
        "outputId": "aea631d3-b001-4cbc-fc74-93ca64e35bc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#### Data description #### \r\n",
            "The attached file `historical_data.csv` contains a subset of deliveries received at DoorDash in early 2015 in a subset of the cities. Each row in this file corresponds to one unique delivery. Each column corresponds to a feature as explained below. Note all money (dollar) values given in the data are in cents and all time duration values given are in seconds \r\n",
            "The target value to predict here is the total seconds value between `created_at` and `actual_delivery_time`. \r\n",
            "\r\n",
            "We have added noise to the dataset to obfuscate certain business details. Both `historical_data.csv` and `data_to_predict.json` include similar noise. We will only be evaluating your model's performance on this noisy, artificial dataset. The baseline model we will compare it was also trained and evaluated on the same noisy dataset.\r\n",
            "\r\n",
            "#### Columns in historical_data.csv\r\n",
            "\r\n",
            "### Time features\r\n",
            "market_id: A city/region in which DoorDash operates, e.g., Los Angeles, given in the data as an id\r\n",
            "created_at: Timestamp in UTC when the order was submitted by the consumer to DoorDash. (Note this timestamp is in UTC, but in case you need it, the actual timezone of the region was US/Pacific)\r\n",
            "actual_delivery_time: Timestamp in UTC when the order was delivered to the consumer\r\n",
            "\r\n",
            "### Store features \r\n",
            "store_id: an id representing the restaurant the order was submitted for\r\n",
            "store_primary_category: cuisine category of the restaurant, e.g., italian, asian\r\n",
            "order_protocol: a store can receive orders from DoorDash through many modes. This field represents an id denoting the protocol\r\n",
            "\r\n",
            "### Order features\r\n",
            "total_items: total number of items in the order\r\n",
            "subtotal: total value of the order submitted (in cents)\r\n",
            "num_distinct_items: number of distinct items included in the order\r\n",
            "min_item_price: price of the item with the least cost in the order (in cents)\r\n",
            "max_item_price: price of the item with the highest cost in the order (in cents)\r\n",
            "\r\n",
            "### Market features\r\n",
            "DoorDash being a marketplace, we have information on the state of marketplace when the order is placed, that can be used to estimate delivery time. The following features are values at the time of `created_at` (order submission time)\r\n",
            "total_onshift_dashers: Number of available dashers who are within 10 miles of the store at the time of order creation \r\n",
            "total_busy_dashers: Subset of above `total_onshift_dashers` who are currently working on an order\r\n",
            "total_outstanding_orders: Number of orders within 10 miles of this order that are currently being processed.\r\n",
            "\r\n",
            "### Predictions from other models:\r\n",
            "We have predictions from other models for various stages of delivery process that we can use.\r\n",
            "estimated_order_place_duration: Estimated time for the restaurant to receive the order from DoorDash (in seconds)\r\n",
            "estimated_store_to_consumer_driving_duration: Estimated travel time between store and consumer (in seconds)\r\n",
            "\r\n",
            "\r\n",
            "\r\n",
            "#####################################################################################\r\n",
            "#### Data to predict #### \r\n",
            "Also attached here is `data_to_predict.json`, which provides the new data that you must predict on using the model you build. This data was generated similar to the `historical_data.csv` and it contains the same columns as above, except for the following differences:\r\n",
            "  * This file does not contain `actual_delivery_time`, since that is unknown at the time of prediction\r\n",
            "  * This file contains `delivery_id` as additional field\r\n",
            "  * This file may contain other additional fields\r\n",
            "Each row of the data is one data point to predict on. Note that `data_to_predict.json` contains orders from later weeks compared to `historical_data` \r\n"
          ]
        }
      ],
      "source": [
        "!cat data_description.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b1cf3a13",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1cf3a13",
        "outputId": "988b5d0d-fe35-4c78-d7fd-4effc9f80899"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'takehomes'...\n",
            "remote: Enumerating objects: 1768, done.\u001b[K\n",
            "remote: Counting objects: 100% (576/576), done.\u001b[K\n",
            "remote: Compressing objects: 100% (455/455), done.\u001b[K\n",
            "remote: Total 1768 (delta 169), reused 481 (delta 120), pack-reused 1192\u001b[K\n",
            "Receiving objects: 100% (1768/1768), 297.30 MiB | 13.86 MiB/s, done.\n",
            "Resolving deltas: 100% (619/619), done.\n",
            "/content/takehomes/doordash_1\n",
            "data_description.txt  historical_data.csv  metadata.json\n",
            "data_to_predict.json  logo.png\t\t   takehomefile.ipynb\n"
          ]
        }
      ],
      "source": [
        "!git clone --branch doordash_1 https://github.com/interviewquery/takehomes.git\n",
        "%cd takehomes/doordash_1\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "043940d3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "043940d3",
        "outputId": "ee358eea-61af-426e-f2c4-eb7adbeff818"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   market_id           created_at actual_delivery_time  store_id  \\\n",
            "0        1.0  2015-02-06 22:24:17  2015-02-06 23:27:16      1845   \n",
            "1        2.0  2015-02-10 21:49:25  2015-02-10 22:56:29      5477   \n",
            "2        3.0  2015-01-22 20:39:28  2015-01-22 21:09:09      5477   \n",
            "3        3.0  2015-02-03 21:21:45  2015-02-03 22:13:00      5477   \n",
            "4        3.0  2015-02-15 02:40:36  2015-02-15 03:20:26      5477   \n",
            "\n",
            "  store_primary_category  order_protocol  total_items  subtotal  \\\n",
            "0               american             1.0            4      3441   \n",
            "1                mexican             2.0            1      1900   \n",
            "2                    NaN             1.0            1      1900   \n",
            "3                    NaN             1.0            6      6900   \n",
            "4                    NaN             1.0            3      3900   \n",
            "\n",
            "   num_distinct_items  min_item_price  max_item_price  total_onshift_dashers  \\\n",
            "0                   4             557            1239                   33.0   \n",
            "1                   1            1400            1400                    1.0   \n",
            "2                   1            1900            1900                    1.0   \n",
            "3                   5             600            1800                    1.0   \n",
            "4                   3            1100            1600                    6.0   \n",
            "\n",
            "   total_busy_dashers  total_outstanding_orders  \\\n",
            "0                14.0                      21.0   \n",
            "1                 2.0                       2.0   \n",
            "2                 0.0                       0.0   \n",
            "3                 1.0                       2.0   \n",
            "4                 6.0                       9.0   \n",
            "\n",
            "   estimated_order_place_duration  \\\n",
            "0                             446   \n",
            "1                             446   \n",
            "2                             446   \n",
            "3                             446   \n",
            "4                             446   \n",
            "\n",
            "   estimated_store_to_consumer_driving_duration  \n",
            "0                                         861.0  \n",
            "1                                         690.0  \n",
            "2                                         690.0  \n",
            "3                                         289.0  \n",
            "4                                         650.0  \n"
          ]
        }
      ],
      "source": [
        "# Write your code here\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load the historical data\n",
        "df = pd.read_csv('historical_data.csv')\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.dtypes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xSr94QQ1cVQ",
        "outputId": "1da71c32-c2c1-4087-b28f-d06d7dde06ee"
      },
      "id": "3xSr94QQ1cVQ",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "market_id                                       float64\n",
            "created_at                                       object\n",
            "actual_delivery_time                             object\n",
            "store_id                                          int64\n",
            "store_primary_category                           object\n",
            "order_protocol                                  float64\n",
            "total_items                                       int64\n",
            "subtotal                                          int64\n",
            "num_distinct_items                                int64\n",
            "min_item_price                                    int64\n",
            "max_item_price                                    int64\n",
            "total_onshift_dashers                           float64\n",
            "total_busy_dashers                              float64\n",
            "total_outstanding_orders                        float64\n",
            "estimated_order_place_duration                    int64\n",
            "estimated_store_to_consumer_driving_duration    float64\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Convert timestamps to datetime objects\n",
        "df['created_at'] = pd.to_datetime(df['created_at'])\n",
        "df['actual_delivery_time'] = pd.to_datetime(df['actual_delivery_time'])\n",
        "\n",
        "# Extract time-based features\n",
        "df['day_of_week'] = df['created_at'].dt.dayofweek\n",
        "df['hour_of_day'] = df['created_at'].dt.hour\n",
        "\n",
        "# Calculate the target variable: total delivery duration in seconds\n",
        "df['delivery_duration_seconds'] = (df['actual_delivery_time'] - df['created_at']).dt.total_seconds()\n",
        "\n",
        "# Drop unnecessary columns\n",
        "X = df.drop(['created_at', 'actual_delivery_time'], axis=1)\n",
        "y = df['delivery_duration_seconds']\n",
        "\n",
        "# Perform one-hot encoding for the 'store_primary_category' column\n",
        "X = pd.get_dummies(X, columns=['store_primary_category'], drop_first=True)\n",
        "\n",
        "# Use SimpleImputer to handle missing values in X\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = imputer.fit_transform(X)\n",
        "\n",
        "# Use SimpleImputer to handle missing values in y\n",
        "imputer_y = SimpleImputer(strategy='mean')\n",
        "y_imputed = imputer_y.fit_transform(y.values.reshape(-1, 1)).ravel()\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y_imputed, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature engineering - you can add more features based on your insights\n",
        "# ...\n",
        "\n",
        "# Build the Random Forest Regressor model\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model using RMSE\n",
        "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "print(\"Root Mean Squared Error (RMSE) on the test set:\", rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PK2-ulFF2Kv-",
        "outputId": "4e9c8be8-cf8f-413d-f0bb-add1836c5667"
      },
      "id": "PK2-ulFF2Kv-",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error (RMSE) on the test set: 458.357646721439\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output shows the Root Mean Squared Error (RMSE) on the test set, which is approximately 458.36 seconds. The RMSE represents the average difference between the predicted delivery durations and the actual delivery durations in the test set.\n",
        "\n",
        "An RMSE of 458.36 seconds means that, on average, the model's predictions deviate from the actual delivery durations by approximately 458.36 seconds. Lower RMSE values indicate better performance, as they suggest that the model's predictions are closer to the true delivery durations.\n",
        "\n",
        "Now Part 1 of the exercise is done. For Part 2, we need to write an application that accepts data from the data_to_predict.json file, uses the trained model to make predictions for each delivery, and writes out the predictions to a new tab-separated file (tsv) with columns - delivery_id and predicted_delivery_seconds.\n"
      ],
      "metadata": {
        "id": "v7uQuoTQS4Oz"
      },
      "id": "v7uQuoTQS4Oz"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}